---
sidebar_position: 1
---

# Deployment Setup

## Prerequisites

Before running the project locally, ensure you have:

- **Docker Desktop** (v24+) and **Docker Compose** v2
- **Node.js** v18+ and **pnpm** (for frontend development)
- **Python** 3.11+ (for backend development without Docker)
- A **Google Cloud** project with the Gemini API enabled
- A **Supabase** project (or a local PostgreSQL instance)
- A **Redis** instance (Upstash is recommended for cloud; Docker for local)

---

## Environment Variables

Both services read configuration from `.env` files. Copy the example files and fill in your values:

```bash
cp UGM-AICare/backend/env.example UGM-AICare/backend/.env
cp UGM-AICare/frontend/env.example UGM-AICare/frontend/.env.local
```

### Critical Backend Variables

```bash
# Database
DATABASE_URL=postgresql+asyncpg://user:pass@host:5432/aicare

# Redis
REDIS_URL=redis://localhost:6379

# Google AI
GOOGLE_API_KEY=your_gemini_api_key

# Langfuse (observability — optional but recommended)
LANGFUSE_PUBLIC_KEY=pk-lf-...
LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_HOST=https://cloud.langfuse.com

# JWT
SECRET_KEY=your_jwt_secret_minimum_32_characters
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=1440

# Privacy
USER_HASH_SECRET=your_hmac_secret_for_pseudonymisation
```

### Critical Frontend Variables

```bash
NEXTAUTH_URL=http://localhost:22000
NEXTAUTH_SECRET=your_nextauth_secret
NEXT_PUBLIC_API_URL=http://localhost:22001
```

---

## Running with Docker Compose

The full stack (backend + frontend) can be started with one command. The database and Redis are treated as **external services** configured via `.env` — they are not part of the Compose file.

```bash
# Development mode (hot reload on both frontend and backend)
docker compose --env-file .env \
  -f docker-compose.base.yml \
  -f docker-compose.dev.yml \
  up -d

# Or using the convenience script
./run_dev.sh
```

Once running:
- Frontend: `http://localhost:22000`
- Backend API: `http://localhost:22001`
- API docs (auto-generated by FastAPI): `http://localhost:22001/docs`

---

## Running Without Docker

### Backend

```bash
cd backend

# Create and activate a virtual environment
python -m venv .venv
source .venv/bin/activate      # Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run database migrations
alembic upgrade head

# Start the server
uvicorn app.main:app --host 0.0.0.0 --port 22001 --reload
```

### Frontend

```bash
cd frontend

# Install dependencies
pnpm install

# Start the development server
pnpm dev
```

---

## Running Migrations

```bash
# Apply all pending migrations
alembic upgrade head

# Generate a new migration after changing a SQLAlchemy model
alembic revision --autogenerate -m "your migration description"

# Roll back the last migration
alembic downgrade -1
```

---

## Production Deployment

The production deployment uses two separate containers behind Nginx:

```
Internet → Nginx (TLS termination)
              ├── aicare.sumbu.xyz      → Frontend container (Next.js, port 3000)
              └── api.aicare.sumbu.xyz  → Backend container (FastAPI, port 8000)
```

Deploy to production using the provided script:

```bash
./deploy-prod.sh
```

This script:
1. Pulls the latest images from the container registry
2. Runs `alembic upgrade head` as a pre-deploy step
3. Performs a rolling restart (zero downtime)
4. Runs a health check — rolls back automatically if the health endpoint fails

---

## Observability

Once deployed, system health is visible across three surfaces:

| Tool | URL | What It Shows |
| --- | --- | --- |
| **FastAPI Swagger UI** | `/docs` | All API endpoints, schemas, try-it-now |
| **Langfuse** | `cloud.langfuse.com` | Every LLM trace, tool call, latency, token cost |
| **Grafana** | Internal dashboard | Infrastructure metrics — CPU, memory, DB connections, Redis latency |
