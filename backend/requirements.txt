# ============================================
# UGM-AICare Backend Dependencies
# ============================================
# Version Pinning Strategy:
# - Exact versions (==): Security-critical or known stable versions
# - Constrained ranges (>=X,<Y): Allows patches, prevents breaking changes
# - This reduces pip backtracking and ensures reproducible builds
# - Last updated: October 31, 2025
# ============================================

# Web Framework
fastapi>=0.115.5,<0.116.0
uvicorn>=0.30.0,<1.0.0
pydantic>=2.9.0,<3.0.0
python-multipart>=0.0.18  # Updated to fix CVE-2024-24762 and CVE-2024-53981

# HTTP Client
requests==2.31.0
httpx>=0.28.0,<1.0.0  # Updated for anyio>=4 compatibility
minio==7.2.9
beautifulsoup4==4.12.3

# Database and ORM
sqlalchemy[asyncio]==2.0.21
alembic>=1.13.0,<2.0.0
redis==5.0.1
asyncpg>=0.29.0  # Fast PostgreSQL Database Client Library for Python/asyncio
psycopg2-binary>=2.9.0  # For Alembic migrations (sync operations)
aiosqlite  # For async SQLite support (dev/testing only)
aiofiles>=23.0.0 # For async file operations
PyPDF2==3.0.1

# Authentication
python-jose[cryptography]>=3.4.0  # Updated to fix CVE-2024-33663
passlib[bcrypt]==1.7.4
bcrypt==4.0.1
python-dotenv
hkdf

# Testing
pytest>=8.0.0
pytest-asyncio>=0.24.0  # Updated for anyio>=4 compatibility

# AI and ML
# Google AI - NEW UNIFIED SDK (migrated from google-generativeai)
# Old SDK deprecated Nov 30, 2025: https://pypi.org/project/google-generativeai/
google-genai>=1.33.0
google-api-core>=2.19.0,<3.0.0  # Constrain to avoid excessive backtracking
googleapis-common-protos>=1.70.0,<2.0.0  # Explicit pin prevents resolver backtracking
protobuf>=5.0.0,<6.0.0  # Compatible with google-genai, Langfuse, and ONNX
opentelemetry-sdk==1.35.0  # Align OpenTelemetry stack for Langfuse
opentelemetry-proto==1.35.0
opentelemetry-exporter-otlp-proto-http==1.35.0
opentelemetry-exporter-otlp-proto-common==1.35.0

# LangGraph
langgraph>=0.2.0,<0.3.0
langfuse>=2.0.0  # LLM observability and agent tracing

# ONNX Runtime for Crisis Detection (3-5x faster, 96% smaller than PyTorch)
# Replaces: torch (800+ MB) + sentence-transformers
onnxruntime>=1.16.0,<2.0.0  # Optimized inference runtime
onnx>=1.15.0,<2.0.0  # For ONNX model optimization (pre-built wheels)

# Blockchain Integration
web3>=6.0.0,<7.0.0  # Web3.py for Ethereum/SOMNIA blockchain interaction
transformers>=4.41.0,<5.0.0  # For tokenizer (still needed, but much lighter without torch)

# Torch - Only needed for ONNX export (can be removed after first build)
# The ensure_onnx_model.py script will download the model and export to ONNX
# After that, torch can be uninstalled - runtime only needs onnxruntime
# CPU-only version to avoid 2GB+ CUDA downloads
torch>=2.0.0,<3.0.0

# Statistical Analysis and Privacy
numpy>=1.24.0,<2.0.0

# Social Media Integration
tweepy==4.14.0  # For Twitter/X API integration

# Task Scheduling
celery==5.3.4
apscheduler==3.10.4

# Utils
python-slugify==8.0.1
pydantic-settings==2.0.3
typing-extensions

# Monitoring
prometheus-client==0.19.0
prometheus-fastapi-instrumentator==7.1.0


# Development Tools
black==23.9.1
isort==5.12.0
flake8==6.1.0

gunicorn>=20.1.0  # For production server
spacy==3.7.5
