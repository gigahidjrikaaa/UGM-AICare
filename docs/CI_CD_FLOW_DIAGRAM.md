# CI/CD Pipeline Flow with Test Failure Handling

**Last Updated:** October 31, 2025

## Visual Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        TRIGGER: Push to main                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                         â”‚
        â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  validate-env     â”‚                    â”‚  detect-changes   â”‚
â”‚  âœ“ Check secrets  â”‚                    â”‚  âœ“ Backend files  â”‚
â”‚  âœ“ Validate vars  â”‚                    â”‚  âœ“ Frontend files â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                         â”‚
         â–¼                                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASS?  â”‚                          â”‚                   â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                          â”‚                   â”‚
        â”‚                               â–¼                   â–¼
        â”‚ YES                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚ test-backend â”‚    â”‚test-frontend â”‚
        â”‚                       â”‚ continue-on- â”‚    â”‚ continue-on- â”‚
        â”‚                       â”‚ error: true  â”‚    â”‚ error: true  â”‚
        â”‚                       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                              â”‚                   â”‚
        â”‚                              â–¼                   â–¼
        â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚ TESTS FAIL?  â”‚    â”‚ TESTS FAIL?  â”‚
        â”‚                       â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
        â”‚                          â”‚       â”‚           â”‚       â”‚
        â”‚                   PASS â”€â”€â”˜       â””â”€â”€ FAIL   â”‚       â””â”€â”€ FAIL
        â”‚                          â”‚           â”‚      â”‚           â”‚
        â”‚                          â–¼           â–¼      â–¼           â–¼
        â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚   Generate Test Summary         â”‚
        â”‚                       â”‚   â€¢ Show passed/failed counts   â”‚
        â”‚                       â”‚   â€¢ Display failure details     â”‚
        â”‚                       â”‚   â€¢ Upload artifacts            â”‚
        â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                    â”‚
        â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                               â”‚
        â–¼                    â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  All jobs pass    â”‚  â”‚build-backend â”‚           â”‚build-frontendâ”‚
â”‚  or continue on   â”‚  â”‚ Checks test  â”‚           â”‚ Checks test  â”‚
â”‚  failure          â”‚  â”‚ status, adds â”‚           â”‚ status, adds â”‚
â”‚                   â”‚  â”‚ warning if   â”‚           â”‚ warning if   â”‚
â”‚                   â”‚  â”‚ failed       â”‚           â”‚ failed       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚                          â”‚
          â”‚                   â–¼                          â–¼
          â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚            â”‚ scan-backend â”‚          â”‚scan-frontend â”‚
          â”‚            â”‚ Trivy scan   â”‚          â”‚ Trivy scan   â”‚
          â”‚            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚                          â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚    deploy     â”‚
                      â”‚ â€¢ Deploy app  â”‚
                      â”‚ â€¢ Show test   â”‚
                      â”‚   status      â”‚
                      â”‚ â€¢ Warning if  â”‚
                      â”‚   tests failedâ”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚   Summary     â”‚
                      â”‚ âœ… Deployed   â”‚
                      â”‚ âš ï¸  Test      â”‚
                      â”‚    warnings   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Detailed Stage Breakdown

### Stage 1: Environment Validation

**Job:** `validate-env`

```yaml
Status: MUST PASS (blocking)
Duration: ~30 seconds
```

**Checks:**
- ENV_FILE_PRODUCTION secret exists
- All critical variables are set
- No default/example values remain
- Important variables present (warnings only)

**On Failure:** Pipeline stops immediately

---

### Stage 2: Change Detection

**Job:** `detect-changes`

```yaml
Status: MUST PASS (blocking)
Duration: ~10 seconds
```

**Detects:**
- Backend file changes
- Frontend file changes
- Skips tests/builds for unchanged components

**On Failure:** Pipeline stops

---

### Stage 3: Testing (Parallel)

**Jobs:** `test-backend`, `test-frontend`

```yaml
Status: NON-BLOCKING (continue-on-error: true)
Duration: 1-3 minutes per job
```

**Backend Tests:**
```bash
pytest --verbose --tb=short --junit-xml=test-results.xml
```
- Runs all pytest tests
- Generates JUnit XML report
- Captures full output
- **Continues even if tests fail**

**Frontend Tests:**
```bash
npm test -- --verbose --json --outputFile=test-results.json
```
- Runs all Jest tests
- Generates JSON report
- Captures full output
- **Continues even if tests fail**

**Outputs:**
1. **Test Summary** (GitHub Actions UI):
   - Pass/fail counts
   - Failed test names
   - Error details (first 50 lines)
   - Warning message

2. **Test Artifacts** (30-day retention):
   - `test-results.xml` / `test-results.json`
   - `test-output.txt`

**On Failure:** Job marked as failed, but pipeline continues

---

### Stage 4: Build (Parallel)

**Jobs:** `build-backend`, `build-frontend`

```yaml
Status: Proceeds if tests passed OR failed
Duration: 3-5 minutes per job
```

**Backend Build:**
- Checks test status from `needs.test-backend.result`
- Adds warning to summary if tests failed
- Builds Docker image
- Pushes to GHCR with commit SHA tag

**Frontend Build:**
- Checks test status from `needs.test-frontend.result`
- Adds warning to summary if tests failed
- Builds Docker image
- Pushes to GHCR with commit SHA tag

**Build Conditions:**
```yaml
if: |
  always() && 
  (needs.test-backend.result == 'success' || 
   needs.test-backend.result == 'failure' || 
   needs.test-backend.result == 'skipped')
```

**On Test Failure:** Adds this to summary:
```
âš ï¸ WARNING: Building despite test failures. 
Review test results before deploying.
```

---

### Stage 5: Security Scanning (Parallel)

**Jobs:** `scan-backend`, `scan-frontend`

```yaml
Status: MUST PASS (blocking)
Duration: 2-4 minutes per job
```

**Trivy Scans:**
- Vulnerability scanning
- High/Critical severity detection
- SARIF report generation

**On Failure:** Pipeline stops (security critical)

---

### Stage 6: Deployment

**Job:** `deploy`

```yaml
Status: Final stage
Duration: 2-5 minutes
Dependencies: All previous jobs
```

**Pre-Deploy Checks:**
```yaml
needs.validate-env.result == 'success' &&
(needs.build-backend.result == 'success' || 'skipped') &&
(needs.build-frontend.result == 'success' || 'skipped') &&
(needs.scan-backend.result == 'success' || 'skipped') &&
(needs.scan-frontend.result == 'success' || 'skipped')
```

**Deployment Steps:**
1. SSH to production VM
2. Pull latest code
3. Write .env file
4. Run `deploy.sh` with commit SHA
5. Optionally deploy monitoring stack

**Post-Deploy:**
1. **Generate Deployment Summary**:
   ```markdown
   # íº€ Deployment Summary
   
   **Environment:** Production
   **SHA:** abc123def456
   **Monitoring:** true
   
   ## Test Status
   - âœ… Backend Tests: PASSED
   - âš ï¸ Frontend Tests: FAILED (deployment continued)
   
   ## âš ï¸ Warning
   Deployment proceeded despite test failures. Please:
   1. Review test failure details
   2. Download test artifacts
   3. Monitor production logs
   4. Consider rollback if critical
   5. Fix tests in next commit
   ```

2. **Verify Monitoring Stack** (if enabled):
   - Check Prometheus health
   - Check Grafana health
   - Check Elasticsearch health
   - Check Langfuse health

---

## Test Failure Scenarios

### Scenario 1: Backend Tests Fail

```
test-backend: âŒ FAILURE
  â†“ (continues anyway)
build-backend: âš ï¸ BUILDS WITH WARNING
  â†“
scan-backend: âœ… PASS
  â†“
deploy: âš ï¸ DEPLOYS WITH WARNING

Summary shows:
- Backend Tests: FAILED (deployment continued)
- Warning message with action items
```

### Scenario 2: Frontend Tests Fail

```
test-frontend: âŒ FAILURE
  â†“ (continues anyway)
build-frontend: âš ï¸ BUILDS WITH WARNING
  â†“
scan-frontend: âœ… PASS
  â†“
deploy: âš ï¸ DEPLOYS WITH WARNING

Summary shows:
- Frontend Tests: FAILED (deployment continued)
- Warning message with action items
```

### Scenario 3: Both Tests Fail

```
test-backend: âŒ FAILURE
test-frontend: âŒ FAILURE
  â†“ (both continue)
build-backend: âš ï¸ BUILDS WITH WARNING
build-frontend: âš ï¸ BUILDS WITH WARNING
  â†“
scan-*: âœ… PASS
  â†“
deploy: âš ï¸âš ï¸ DEPLOYS WITH MULTIPLE WARNINGS

Summary shows:
- Backend Tests: FAILED (deployment continued)
- Frontend Tests: FAILED (deployment continued)
- Strong warning message
- Recommendation to monitor closely
```

### Scenario 4: Security Scan Fails

```
test-*: âœ… PASS
  â†“
build-*: âœ… PASS
  â†“
scan-backend: âŒ CRITICAL VULNERABILITIES
  â†“
deploy: íº« BLOCKED

Pipeline stops - no deployment
Security issues must be fixed first
```

---

## Accessing Test Results

### 1. GitHub Actions UI

**Path:** Repository â†’ Actions â†’ Select workflow run

**Summary Tab:**
- Test pass/fail counts
- Failed test details
- Build warnings
- Deployment summary

### 2. Download Artifacts

**Path:** Workflow run â†’ Scroll to bottom â†’ Artifacts section

**Available Downloads:**
- `backend-test-results.zip`
  - test-results.xml (JUnit format)
  - test-output.txt (full pytest output)

- `frontend-test-results.zip`
  - test-results.json (Jest format)
  - test-output.txt (full test output)

**Retention:** 30 days

### 3. Job Logs

**Path:** Workflow run â†’ Click job name â†’ Expand steps

**Shows:**
- Real-time test execution
- Full command output
- Error tracebacks
- Environment details

---

## Rollback Procedures

### Via GitHub Actions (Recommended)

```yaml
1. Go to Actions â†’ CI/CD Pipeline
2. Click "Run workflow"
3. Select branch: main
4. Enter rollback_sha: <previous-working-commit>
5. Click "Run workflow"
```

### Via SSH (Emergency)

```bash
ssh user@production-server
cd /path/to/UGM-AICare
./deploy-prod.sh rollback abc123def456
```

### Find Previous Working SHA

```bash
# List recent commits
git log --oneline -10

# Check Actions history
# Go to Actions â†’ Find last successful run â†’ Copy SHA
```

---

## Configuration Reference

### Make Tests Blocking

Edit `.github/workflows/ci.yml`:

```yaml
- name: Run backend tests (pytest)
  id: backend-tests
  # Remove this line to make tests blocking:
  # continue-on-error: true
  run: pytest
```

### Adjust Artifact Retention

```yaml
- name: Upload Backend Test Results
  uses: actions/upload-artifact@v4
  with:
    retention-days: 90  # Change from 30 to 90 days
```

### Add Critical Test Job

```yaml
test-critical:
  runs-on: ubuntu-latest
  steps:
    - name: Run critical tests
      run: pytest tests/critical/ --maxfail=1
      # No continue-on-error - must pass
```

---

## Monitoring Test Health

### Key Metrics

Track in your team:

1. **Test Pass Rate**
   - % of runs with all tests passing
   - Target: >95%

2. **Test Execution Time**
   - Average duration per job
   - Watch for slowdowns

3. **Failure Recovery Time**
   - Time from failure to fix
   - Target: <24 hours

4. **Artifact Download Rate**
   - How often devs download artifacts
   - Indicates engagement with failures

### GitHub Insights

**Path:** Actions â†’ CI/CD Pipeline â†’ "..." menu â†’ View workflow insights

**Shows:**
- Success rate over time
- Average execution duration
- Failure patterns

---

## Best Practices Summary

âœ… **DO:**
- Review test summaries after every deployment
- Download artifacts for investigation
- Fix failing tests within 24 hours
- Monitor production after deploying with failures
- Keep tests fast (<3 minutes)

âŒ **DON'T:**
- Ignore test failures
- Let broken tests accumulate
- Deploy without checking summary
- Skip artifact review for complex failures
- Disable tests instead of fixing them

---

**Related Documentation:**
- [CI/CD Test Behavior Guide](./CI_CD_TEST_BEHAVIOR.md)
- [Production Monitoring Guide](./PRODUCTION_MONITORING_GUIDE.md)
- [Development Workflow](./development-workflow.md)

---

**Maintained By:** UGM-AICare DevOps Team
**Last Updated:** October 31, 2025
