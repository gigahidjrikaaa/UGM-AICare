# Production deployment configuration
#
# Optional stacks are enabled via Docker Compose profiles:
#   - monitoring: Prometheus + Grafana + exporters + Langfuse
#   - elk: Elasticsearch + Logstash + Kibana + Filebeat
#   - loki: Loki + Promtail

services:
  #################
  # Database (PostgreSQL)
  #################
  db:
    image: postgres:16-alpine
    container_name: ugm_aicare_db_prod
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-aicare_db}
      POSTGRES_USER: ${POSTGRES_USER:-giga}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - pgdata_prod:/var/lib/postgresql/data
    ports:
      - "${DB_EXTERNAL_PORT:-20003}:5432"
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h localhost -U ${POSTGRES_USER:-giga} -d ${POSTGRES_DB:-aicare_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ugm_aicare_network

  #################
  # Object Storage (MinIO)
  #################
  minio:
    image: minio/minio:RELEASE.2025-09-07T16-13-09Z
    container_name: ugm_aicare_minio_prod
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY}
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY}
    command: server /data --console-address ":9001"
    volumes:
      - minio_data_prod:/data
    ports:
      - "${MINIO_EXTERNAL_PORT:-20005}:9000"
      - "${MINIO_CONSOLE_PORT:-20006}:9001"
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - ugm_aicare_network

  #################
  # Migration Service
  #################
  migrate:
    container_name: ugm_aicare_migrate_prod
    build:
      context: ../../backend
      dockerfile: app/Dockerfile.migrate
    entrypoint: >
      bash -c "
        /app/scripts/wait-for-it.sh db:5432 -t 60 -- echo 'Database is ready!' &&
        echo 'Running Alembic migrations...' &&
        alembic upgrade head
      "
    env_file:
      - ../../.env
    environment:
      PYTHONPATH: /app
      DATABASE_URL: postgresql+asyncpg://${POSTGRES_USER:-giga}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB:-aicare_db}
    depends_on:
      db:
        condition: service_healthy
    networks:
      - ugm_aicare_network

  #################
  # Backend (FastAPI)
  #################
  backend:
    container_name: ugm_aicare_backend_prod
    image: ${BACKEND_IMAGE:-ugm-aicare-api:local}
    build:
      context: ../../backend
      dockerfile: app/Dockerfile
    ports:
      - "${BACKEND_EXTERNAL_PORT:-20002}:8000"
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 1G
    env_file:
      - ../../.env
    environment:
      DATABASE_URL: postgresql+asyncpg://${POSTGRES_USER:-giga}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB:-aicare_db}
      MINIO_ENDPOINT: minio:9000
      APP_ENV: production
      LANGFUSE_ENABLED: "false"
    depends_on:
      migrate:
        condition: service_completed_successfully
      db:
        condition: service_healthy
      minio:
        condition: service_started
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ugm_aicare_network

  #################
  # Frontend (Next.js)
  #################
  frontend:
    container_name: ugm_aicare_frontend_prod
    image: ${FRONTEND_IMAGE:-ugm-aicare-web:local}
    build:
      context: ../../frontend
      dockerfile: Dockerfile
      target: production
      args:
        NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL}
    ports:
      - "${FRONTEND_EXTERNAL_PORT:-20001}:3000"
    deploy:
      resources:
        limits:
          memory: 6G
        reservations:
          memory: 2G
    env_file:
      - ../../.env
    environment:
      NODE_ENV: production
      PORT: 3000
      INTERNAL_API_URL: http://backend:8000
    depends_on:
      - backend
    restart: always
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ugm_aicare_network

  #################
  # Monitoring Stack (optional)
  #################
  prometheus:
    profiles: ["monitoring"]
    build:
      context: ../monitoring/prometheus
      dockerfile: Dockerfile
    container_name: ugm_aicare_prometheus_prod
    user: root
    ports:
      - "8255:9090"
    volumes:
      - prometheus-data-prod:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - monitoring
      - ugm_aicare_network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

  grafana:
    profiles: ["monitoring"]
    image: grafana/grafana:10.2.2
    container_name: ugm_aicare_grafana_prod
    ports:
      - "8256:3000"
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD?Set GRAFANA_ADMIN_PASSWORD in env}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_SERVER_ROOT_URL: ${GRAFANA_ROOT_URL:-http://localhost:8256}
      GF_ANALYTICS_REPORTING_ENABLED: "false"
      GF_ANALYTICS_CHECK_FOR_UPDATES: "false"
    volumes:
      - grafana-data-prod:/var/lib/grafana
      - ../monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ../monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    networks:
      - monitoring
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

  node-exporter:
    profiles: ["monitoring"]
    image: prom/node-exporter:v1.7.0
    container_name: ugm_aicare_node_exporter_prod
    ports:
      - "8257:9100"
    command:
      - '--path.rootfs=/host'
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)' 
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    networks:
      - monitoring
    restart: unless-stopped

  cadvisor:
    profiles: ["monitoring"]
    image: gcr.io/cadvisor/cadvisor:v0.47.2
    container_name: ugm_aicare_cadvisor_prod
    ports:
      - "8258:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg
    networks:
      - monitoring
    restart: unless-stopped

  postgres-exporter:
    profiles: ["monitoring"]
    image: prometheuscommunity/postgres-exporter:v0.15.0
    container_name: ugm_aicare_postgres_exporter_prod
    ports:
      - "8259:9187"
    environment:
      DATA_SOURCE_NAME: "postgresql://${POSTGRES_USER:-giga}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB:-aicare_db}?sslmode=disable"
    networks:
      - monitoring
      - ugm_aicare_network
    restart: unless-stopped

  langfuse-server:
    profiles: ["monitoring"]
    image: ghcr.io/langfuse/langfuse:2
    container_name: ugm_aicare_langfuse_prod
    ports:
      - "8262:3000"
    environment:
      NODE_ENV: production
      DATABASE_URL: "postgresql://${POSTGRES_USER:-giga}:${POSTGRES_PASSWORD}@db:5432/langfuse_db?schema=public"
      NEXTAUTH_URL: ${LANGFUSE_PUBLIC_URL:-http://localhost:8262}
      NEXTAUTH_SECRET: ${LANGFUSE_SECRET?Set LANGFUSE_SECRET in env}
      SALT: ${LANGFUSE_SALT?Set LANGFUSE_SALT in env}
      TELEMETRY_ENABLED: "false"
      LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES: "true"
      HOSTNAME: 0.0.0.0
    depends_on:
      - db
    networks:
      - monitoring
      - ugm_aicare_network
    restart: unless-stopped

  #################
  # Loki Stack (optional)
  #################
  loki:
    profiles: ["loki"]
    image: grafana/loki:2.9.3
    container_name: ugm_aicare_loki_prod
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ../loki/loki-config.yaml:/etc/loki/local-config.yaml:ro
      - loki-data-prod:/loki
    networks:
      - monitoring
    restart: unless-stopped

  promtail:
    profiles: ["loki"]
    image: grafana/promtail:2.9.3
    container_name: ugm_aicare_promtail_prod
    volumes:
      - ../loki/promtail-config.yaml:/etc/promtail/config.yaml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: -config.file=/etc/promtail/config.yaml
    depends_on:
      - loki
    networks:
      - monitoring
    restart: unless-stopped

  #################
  # ELK Stack (optional)
  #################
  elasticsearch:
    profiles: ["elk"]
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: ugm_aicare_elasticsearch_prod
    environment:
      discovery.type: single-node
      ES_JAVA_OPTS: "-Xms1g -Xmx1g"
      xpack.security.enabled: "false"
      xpack.security.http.ssl.enabled: "false"
      http.host: 0.0.0.0
      transport.host: 127.0.0.1
    ports:
      - "8250:9200"
      - "8251:9300"
    volumes:
      - elasticsearch-data-prod:/usr/share/elasticsearch/data
    networks:
      - elk
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  logstash:
    profiles: ["elk"]
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: ugm_aicare_logstash_prod
    volumes:
      - ../elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ../elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
    ports:
      - "8252:5000/tcp"
      - "8252:5000/udp"
      - "8253:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx512m -Xms512m"
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - elk
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9600/_node/stats || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    restart: unless-stopped

  kibana:
    profiles: ["elk"]
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: ugm_aicare_kibana_prod
    ports:
      - "8254:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
      SERVER_NAME: ugm-aicare-kibana
      SERVER_HOST: "0.0.0.0"
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - elk
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  filebeat:
    profiles: ["elk"]
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: ugm_aicare_filebeat_prod
    user: root
    volumes:
      - ../elk/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - filebeat-data-prod:/usr/share/filebeat/data
    command: filebeat -e -strict.perms=false
    depends_on:
      logstash:
        condition: service_healthy
    networks:
      - elk
    restart: unless-stopped

volumes:
  pgdata_prod:
  minio_data_prod:
  prometheus-data-prod:
  grafana-data-prod:
  loki-data-prod:
  elasticsearch-data-prod:
  filebeat-data-prod:

networks:
  ugm_aicare_network:
    driver: bridge
  monitoring:
    driver: bridge
  elk:
    driver: bridge
