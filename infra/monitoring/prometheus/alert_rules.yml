groups:
  - name: ugm_aicare_alerts
    interval: 30s
    rules:
      # ============================================
      # CRITICAL ALERTS
      # ============================================
      
      # High Error Rate
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m])) 
            / 
            sum(rate(http_requests_total[5m]))
          ) > 0.05
        for: 5m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} (threshold: 5%)"
          runbook: "Check backend logs for exceptions"

      # Backend Service Down
      - alert: BackendServiceDown
        expr: up{job="ugm-aicare-backend"} == 0
        for: 1m
        labels:
          severity: critical
          team: ops
        annotations:
          summary: "Backend service is down"
          description: "Backend service {{ $labels.instance }} has been down for more than 1 minute"
          runbook: "Check Docker container status and logs"

      # Database Connection Pool Exhaustion
      - alert: DatabaseConnectionPoolLow
        expr: pg_stat_database_numbackends / pg_settings_max_connections > 0.9
        for: 2m
        labels:
          severity: critical
          team: database
        annotations:
          summary: "Database connection pool near exhaustion"
          description: "{{ $value | humanizePercentage }} of connections in use (threshold: 90%)"
          runbook: "Check for connection leaks or increase pool size"

      # Crisis Escalation Backlog
      - alert: CrisisEscalationBacklog
        expr: rate(crisis_escalations_total[5m]) > 10
        for: 2m
        labels:
          severity: critical
          team: mental-health
        annotations:
          summary: "High crisis escalation rate"
          description: "{{ $value }} crisis escalations per second (threshold: 10/s)"
          runbook: "Check counselor availability and SDA agent status"

      # ============================================
      # WARNING ALERTS
      # ============================================

      # Slow Response Time
      - alert: SlowResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "Slow API response time"
          description: "P95 latency is {{ $value }}s (threshold: 2s)"
          runbook: "Check agent processing time and database query performance"

      # Slow Agent Processing
      - alert: SlowAgentProcessing
        expr: |
          histogram_quantile(0.95, 
            rate(agent_processing_time_seconds_bucket{agent_name!=""}[5m])
          ) > 5
        for: 5m
        labels:
          severity: warning
          team: agents
        annotations:
          summary: "Slow agent processing detected"
          description: "{{ $labels.agent_name }} P95 time is {{ $value }}s (threshold: 5s)"
          runbook: "Check LLM API latency and agent logs"

      # High Memory Usage
      - alert: HighMemoryUsage
        expr: |
          (
            node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes
          ) / node_memory_MemTotal_bytes > 0.9
        for: 5m
        labels:
          severity: warning
          team: ops
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanizePercentage }} (threshold: 90%)"
          runbook: "Check for memory leaks in backend containers"

      # High CPU Usage
      - alert: HighCPUUsage
        expr: |
          100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 85
        for: 5m
        labels:
          severity: warning
          team: ops
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ $value | humanize }}% (threshold: 85%)"
          runbook: "Check container resource limits and load"

      # Low Disk Space
      - alert: LowDiskSpace
        expr: |
          (
            node_filesystem_avail_bytes{mountpoint="/"} 
            / 
            node_filesystem_size_bytes{mountpoint="/"}
          ) < 0.15
        for: 5m
        labels:
          severity: warning
          team: ops
        annotations:
          summary: "Low disk space"
          description: "Only {{ $value | humanizePercentage }} disk space available (threshold: 15%)"
          runbook: "Clean up logs and unused Docker images"

      # Slow LLM API
      - alert: SlowLLMAPI
        expr: histogram_quantile(0.95, rate(llm_api_duration_seconds_bucket[5m])) > 10
        for: 5m
        labels:
          severity: warning
          team: agents
        annotations:
          summary: "Slow LLM API response"
          description: "{{ $labels.model }} P95 latency is {{ $value }}s (threshold: 10s)"
          runbook: "Check Gemini API status and rate limits"

      # High LLM Token Usage
      - alert: HighLLMTokenUsage
        expr: rate(llm_token_usage_total[1h]) > 100000
        for: 10m
        labels:
          severity: warning
          team: cost
        annotations:
          summary: "High LLM token consumption"
          description: "Using {{ $value }} tokens/hour (threshold: 100k/hour)"
          runbook: "Check for prompt optimization opportunities"

      # Intervention Plan Low Completion Rate
      - alert: LowInterventionPlanCompletion
        expr: intervention_plan_completion_rate < 0.3
        for: 30m
        labels:
          severity: warning
          team: mental-health
        annotations:
          summary: "Low intervention plan completion rate"
          description: "Completion rate is {{ $value | humanizePercentage }} (threshold: 30%)"
          runbook: "Review plan quality and user engagement strategies"

      # ============================================
      # INFO ALERTS
      # ============================================

      # High User Activity
      - alert: HighUserActivity
        expr: active_users > 1000
        for: 5m
        labels:
          severity: info
          team: product
        annotations:
          summary: "High user activity"
          description: "{{ $value }} active users (threshold: 1000)"
          runbook: "Monitor system resources"

      # Unusual Crisis Pattern
      - alert: UnusualCrisisPattern
        expr: |
          (
            rate(crisis_escalations_total[1h]) 
            / 
            rate(crisis_escalations_total[1h] offset 24h)
          ) > 2
        for: 30m
        labels:
          severity: info
          team: mental-health
        annotations:
          summary: "Unusual crisis escalation pattern"
          description: "Crisis rate is {{ $value }}x higher than yesterday"
          runbook: "Investigate potential external factors (exams, events)"
